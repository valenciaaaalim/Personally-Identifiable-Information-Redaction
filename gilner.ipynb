{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ad59f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/valencia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04858a65752e4d06820255013f2b53b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# Load the model\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gliner import GLiNER\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"knowledgator/gliner-pii-base-v1.0\"\n",
    "model = GLiNER.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3528e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_labels = [\n",
    "    \"name\",                       # Full names\n",
    "    \"first name\",                 # First names  \n",
    "    \"last name\",                  # Last names\n",
    "    \"name medical professional\",  # Healthcare provider names\n",
    "    \"dob\",                        # Date of birth\n",
    "    \"age\",                        # Age information\n",
    "    \"gender\",                     # Gender identifiers\n",
    "    \"marital status\"              # Marital status\n",
    "]\n",
    "contact_labels = [\n",
    "    \"email address\",          # Email addresses\n",
    "    \"phone number\",           # Phone numbers\n",
    "    \"ip address\",             # IP addresses\n",
    "    \"url\",                    # URLs\n",
    "    \"location address\",       # Street addresses\n",
    "    \"location street\",        # Street names\n",
    "    \"location city\",          # City names\n",
    "    \"location state\",         # State/province names\n",
    "    \"location country\",       # Country names\n",
    "    \"location zip\"            # ZIP/postal codes\n",
    "]\n",
    "financial_labels = [\n",
    "    \"account number\",         # Account numbers\n",
    "    \"bank account\",           # Bank account numbers\n",
    "    \"routing number\",         # Routing numbers\n",
    "    \"credit card\",            # Credit card numbers\n",
    "    \"credit card expiration\", # Card expiration dates  \n",
    "    \"cvv\",                    # CVV/security codes\n",
    "    \"ssn\",                    # Social Security Numbers\n",
    "    \"money\"                   # Monetary amounts\n",
    "]\n",
    "healthcare_labels = [\n",
    "    \"condition\",                    # Medical conditions\n",
    "    \"medical process\",              # Medical procedures\n",
    "    \"drug\",                         # Drugs\n",
    "    \"dose\",                         # Dosage information\n",
    "    \"blood type\",                   # Blood types\n",
    "    \"injury\",                       # Injuries\n",
    "    \"organization medical facility\",# Healthcare facility names\n",
    "    \"healthcare number\",            # Healthcare numbers\n",
    "    \"medical code\"                  # Medical codes\n",
    "]\n",
    "id_labels = [\n",
    "    \"passport number\",       # Passport numbers\n",
    "    \"driver license\",        # Driver's license numbers\n",
    "    \"username\",              # Usernames\n",
    "    \"password\",              # Passwords\n",
    "    \"vehicle id\"             # Vehicle IDs\n",
    "]\n",
    "\n",
    "labels = personal_labels + contact_labels + financial_labels + healthcare_labels + id_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fc950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 512\n",
    "LABELS = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843abb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted output:\n",
      " Hi, my name is [NAME] and my email is [EMAIL_ADDRESS]. I was born on [DOB] and live in [LOCATION_CITY].\n"
     ]
    }
   ],
   "source": [
    "# Input text (simulating an LLM prompt)\n",
    "text = \"Hi, my name is Sarah and my email is sarah@example.com. I was born on January 1st, 1990 and live in Los Angeles.\"\n",
    "\n",
    "# Predict entities\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "# Redact PII from text\n",
    "# Replace entities from end to start to preserve character positions\n",
    "for ent in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
    "    label = ent['label'].upper().replace(\" \", \"_\")\n",
    "    redacted = f\"[{label}]\"\n",
    "    text = text[:ent['start']] + redacted + text[ent['end']:]\n",
    "\n",
    "print(\"Redacted output:\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461756dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunk_sentences(text, max_tokens=MAX_TOKENS):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "        sentence_token_len = len(sentence_tokens)\n",
    "\n",
    "        if current_tokens + sentence_token_len <= max_tokens:\n",
    "            current_chunk.append(sentence)\n",
    "            current_tokens += sentence_token_len\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_tokens = sentence_token_len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def redact_with_gliner(text_chunk, labels):\n",
    "    entities = model.predict_entities(text_chunk, labels)\n",
    "    for ent in sorted(entities, key=lambda x: x[\"start\"], reverse=True):\n",
    "        tag = f\"[{ent['label'].upper().replace(' ', '_')}]\"\n",
    "        text_chunk = text_chunk[:ent[\"start\"]] + tag + text_chunk[ent[\"end\"]:]\n",
    "    return text_chunk\n",
    "\n",
    "def redact_text_pipeline(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    token_count = len(input_ids)\n",
    "    print(f\"\\n📏 Total token count: {token_count}\")\n",
    "\n",
    "    if token_count <= MAX_TOKENS:\n",
    "        print(\"✅ No chunking needed.\")\n",
    "        redacted = redact_with_gliner(text, LABELS)\n",
    "        print(\"\\n🔒 Redacted Output:\\n\", redacted)\n",
    "        return redacted\n",
    "\n",
    "    print(f\"⚠️ Chunking by sentence (via NLTK) to respect token limit...\\n\")\n",
    "    chunks = chunk_sentences(text)\n",
    "\n",
    "    redacted_chunks = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        token_len = len(tokenizer.encode(chunk, add_special_tokens=False))\n",
    "        print(f\"\\n--- Chunk {i+1} (tokens: {token_len}) ---\\n{chunk}\")\n",
    "        redacted = redact_with_gliner(chunk, LABELS)\n",
    "        redacted_chunks.append(redacted)\n",
    "\n",
    "    final_output = \" \".join(redacted_chunks)\n",
    "    print(\"\\n✅ Final Redacted Output:\\n\", final_output)\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caeb58af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📏 Total token count: 580\n",
      "⚠️ Chunking by sentence (via NLTK) to respect token limit...\n",
      "\n",
      "\n",
      "--- Chunk 1 (tokens: 509) ---\n",
      "My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990.\n",
      "\n",
      "--- Chunk 2 (tokens: 71) ---\n",
      "My credit card is 4111-1111-1111-1111. My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 and my email is john.doe@example.com. I was born on July 1st, 1990. My credit card is 4111-1111-1111-1111.\n",
      "\n",
      "✅ Final Redacted Output:\n",
      " My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is John Doe. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on [DOB]. My credit card is [CREDIT_CARD].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is [NAME]. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on July 1st, 1990. My credit card is [CREDIT_CARD]. My name is John Doe. I live at [LOCATION_ADDRESS]. My SSN is [SSN] and my email is [EMAIL_ADDRESS]. I was born on [DOB]. My credit card is [CREDIT_CARD].'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "long_text = (\n",
    "    \"My name is John Doe. I live at 123 Apple St. My SSN is 123-45-6789 \"\n",
    "    \"and my email is john.doe@example.com. I was born on July 1st, 1990. \"\n",
    "    \"My credit card is 4111-1111-1111-1111. \" * 10  # repeat to exceed token limit\n",
    ")\n",
    "\n",
    "redact_text_pipeline(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nbroad/pii-dd-mistral-generated\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ea2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"path/to/train.csv\")\n",
    "print(df.columns)\n",
    "print(df.iloc[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
